{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeju Credit Card Usage Prediction - July\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import preprocessing, metrics\n",
    "import category_encoders as ce\n",
    "\n",
    "\"\"\"\n",
    "For model building, we consider\n",
    "- XGboost Regressor\n",
    "- Random Forest Regressor\n",
    "\"\"\"\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['font.family'] = 'NanumBarunGothic'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read files \n",
    "train_data = pd.read_csv('201901-202003.csv') # Unfortunately, this file is not available for download currently.\n",
    "apr_data = pd.read_csv('202004.csv')\n",
    "submission = pd.read_csv('submission.csv')\n",
    "\n",
    "# Append april data to test data\n",
    "train_data = train_data.append(apr_data)\n",
    "\n",
    "# fill all empty entries with ''\n",
    "train_data = train_data.fillna('')\n",
    "\n",
    "# Drop unnecessary features - the home cities/provinces of the customers are not important\n",
    "train_data.drop(['HOM_SIDO_NM','HOM_CCG_NM'], axis=1, inplace=True)\n",
    "\n",
    "# Rename SEX column\n",
    "train_data.rename(columns={'SEX_CTGO_CD':'SEX'}, inplace=True)\n",
    "\n",
    "# change data type of SEX column\n",
    "train_data['SEX'] = train_data['SEX'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict of {SIDO: [CCG]} - Make dictionary of Province: City Lists\n",
    "SIDO_CCG_dict = {}\n",
    "\n",
    "# List of all unique CARD_SIDO_NM\n",
    "sidos = list(train_data['CARD_SIDO_NM'].unique())\n",
    "\n",
    "for sido in sidos:\n",
    "    ccgs = list(train_data[train_data['CARD_SIDO_NM'] == sido]['CARD_CCG_NM'].unique())\n",
    "    SIDO_CCG_dict[sido] = ccgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by and keep only useful features\n",
    "train_2 = pd.DataFrame(train_data.groupby(['CARD_CCG_NM','STD_CLSS_NM','AGE','SEX'])['AMT'].sum())\n",
    "train_2.reset_index(inplace=True)\n",
    "train_x = train_2[['CARD_CCG_NM','STD_CLSS_NM','AGE','SEX']]\n",
    "train_y = pd.DataFrame(np.log(train_2['AMT']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now keep the test_data in the same format\n",
    "# Keep only REG_YYMM = 202007\n",
    "test_data = submission[submission['REG_YYMM'] == 202007]\n",
    "\n",
    "test_x = test_data[['CARD_SIDO_NM','STD_CLSS_NM']]\n",
    "test_y = test_data['AMT']\n",
    "\n",
    "# Make the test_x include CARD_CCG_NM as well\n",
    "columns = ['CARD_SIDO_NM','CARD_CCG_NM']\n",
    "SIDO_CCG = pd.DataFrame(columns=columns)\n",
    "\n",
    "for sido in sidos:\n",
    "    for ccg in SIDO_CCG_dict[sido]:\n",
    "        SIDO_CCG = SIDO_CCG.append({'CARD_SIDO_NM':sido, 'CARD_CCG_NM':ccg}, ignore_index=True)\n",
    "        \n",
    "test_x = pd.merge(test_x, SIDO_CCG)\n",
    "\n",
    "test_sido_ccg = test_x[['CARD_SIDO_NM','CARD_CCG_NM']]\n",
    "\n",
    "# Add SEX column\n",
    "temp_sex = pd.DataFrame({'SEX':['1','2']})\n",
    "temp_sex['key'] = 0\n",
    "test_x['key'] = 0\n",
    "\n",
    "test_x = test_x.merge(temp_sex, on='key')\n",
    "\n",
    "# Add AGE column\n",
    "temp_age = pd.DataFrame({'AGE':['10s','20s','30s','40s','50s','60s','70s']})\n",
    "temp_age['key'] = 0\n",
    "test_x = test_x.merge(temp_age, on='key')\n",
    "\n",
    "test_x.drop(['CARD_SIDO_NM','key'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "* There are now only 4 features in our train_x. (STD_CLSS_NM, CARD_CCG_NM, SEX, AGE)\n",
    "* Combine each feature, and use target encodings to convert categorical variables into numerical variables\n",
    "* Both on train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_combine(df_1, df_2):\n",
    "    df_train = df_1.copy()\n",
    "    df_test = df_2.copy()\n",
    "    cat_features = df_train.columns.tolist()\n",
    "    # Iterate through cat_features into 10 different combinations\n",
    "    for features in itertools.combinations(cat_features, 2):\n",
    "        new_feature = features[0] + '_' + features[1]\n",
    "        # Make combined column\n",
    "        df_train[new_feature] = df_train[features[0]] + '_' + df_train[features[1]]\n",
    "        df_test[new_feature] = df_test[features[0]] + '_' + df_test[features[1]]\n",
    "        \n",
    "        # Groupby \n",
    "        df_grouped = pd.DataFrame(train_data.groupby([features[0],features[1]])['AMT'].mean())\n",
    "        df_grouped.reset_index(inplace=True)\n",
    "        df_grouped[new_feature] = df_grouped[features[0]] + '_' + df_grouped[features[1]]\n",
    "        encoder = pd.Series(np.log(df_grouped['AMT'].values), index=df_grouped[new_feature])\n",
    "        \n",
    "        # Encoding process\n",
    "        df_train[new_feature] = df_train[new_feature].map(encoder)\n",
    "        df_test[new_feature] = df_test[new_feature].map(encoder)\n",
    "        \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "train_final_x, test_final_x = feature_combine(train_x, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label Encodings for AGE \n",
    "train_final_x['SEX'] = train_final_x['SEX'].astype('int64')\n",
    "test_final_x['SEX'] = test_final_x['SEX'].astype('int64')\n",
    "\n",
    "# AGE ordinal encoding\n",
    "age_dict = {'10s':1,'70s':2, '20s':3, '60s':4, '30s':5, '40s':6, '50s':7}\n",
    "train_final_x['AGE'] = train_final_x['AGE'].apply(lambda x: age_dict[x])\n",
    "test_final_x['AGE'] = test_final_x['AGE'].apply(lambda x: age_dict[x])\n",
    "\n",
    "# STD_CLSS and CARD_CCG target encoding\n",
    "for feature in ['STD_CLSS_NM','CARD_CCG_NM']:\n",
    "    temp_group = np.log(train_data.groupby([feature])['AMT'].mean())\n",
    "    train_final_x[feature + '_encoded'] = train_final_x[feature].map(temp_group)\n",
    "    test_final_x[feature + '_encoded'] = test_final_x[feature].map(temp_group)\n",
    "    \n",
    "train_final_x.drop(['CARD_CCG_NM','STD_CLSS_NM'], axis=1, inplace=True)\n",
    "test_final_x.drop(['CARD_CCG_NM','STD_CLSS_NM'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check any null value in the test_x entry \n",
    "test_final_x.isna().sum()\n",
    "test_final_x.fillna(0, inplace=True)\n",
    "test_final_x.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column match\n",
    "print(train_final_x.shape, test_final_x.shape)\n",
    "\n",
    "assert(train_final_x.columns.all() == test_final_x.columns.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n",
    "* Check correlation among features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check correlation between each input variable and target\n",
    "corr_df = pd.concat([train_final_x,train_y], axis=1)\n",
    "corr = corr_df.corr()\n",
    "display(corr.style.background_gradient(cmap='coolwarm').set_precision(4))\n",
    "print(corr['AMT'].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection and prediction \n",
    "\n",
    "model_1 = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1, verbose=10)\n",
    "model_1.fit(train_final_x, train_y)\n",
    "print(\"Fit Complete\")\n",
    "prediction = model_1.predict(test_final_x)\n",
    "\n",
    "\"\"\"\n",
    "#model_2 = XGBRegressor(n_estimators=1000, learning_rate=0.01, n_jobs=-1, verbose=10)\n",
    "#model_2.fit(train_x, train_y)\n",
    "#print(\"Fit Complete\")\n",
    "prediction = model_2.predict(apr_x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(np.exp(prediction))\n",
    "prediction.columns = ['AMT']\n",
    "final_df = pd.concat([test_x, prediction], axis=1)\n",
    "\n",
    "# Add CARD_SIDO column\n",
    "final_df = final_df.merge(test_sido_ccg, how='inner', on='CARD_CCG_NM')\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "final_df = pd.DataFrame(final_df.groupby(['CARD_SIDO_NM','STD_CLSS_NM'])['AMT'].sum())\n",
    "final_df.reset_index(inplace=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit the data into submission \n",
    "# First, groupby for REG_YYMM == 202004\n",
    "apr_data = pd.DataFrame(apr_data.groupby(['REG_YYMM','CARD_SIDO_NM','STD_CLSS_NM'])['AMT'].sum())\n",
    "apr_data.reset_index(inplace=True)\n",
    "display(apr_data)\n",
    "\n",
    "# Reinitialize 'AMT' column to 0 before insertion\n",
    "submission['AMT'] = 0\n",
    "\n",
    "# Fill in \n",
    "submission_final = submission.merge(apr_data, how='left', on=['REG_YYMM','STD_CLSS_NM','CARD_SIDO_NM'])\n",
    "submission_final.drop(['id','AMT_x'], axis=1, inplace=True)\n",
    "submission_final.rename(columns={'AMT_y':'AMT'}, inplace=True)\n",
    "submission_final.loc[submission_final['REG_YYMM'] == 202007, 'AMT'] = final_df['AMT'].values\n",
    "submission_final.fillna(0, inplace=True)\n",
    "\n",
    "submission_final.to_csv('submission.csv', encoding='UTF-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
